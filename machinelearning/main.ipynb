{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import file_manager\n",
    "import numpy as np\n",
    "\n",
    "y_train = np.load(\"./vectorizers/labels_train.npy\")\n",
    "y_test = np.load(\"./vectorizers/labels_test.npy\")\n",
    "\n",
    "# Dictionary to store all the different file names of the matrices\n",
    "file_names = {\"bow\": {\"train\": [], \"test\": []}, \"tfidf\": {\"train\": [], \"test\": []}}\n",
    "for file in file_manager.files_in_path(\"./vectorizers\"):\n",
    "    if \"labels\" not in file and \"vect\" not in file and \".gitignore\" not in file:\n",
    "        name = file.split(\"_\")\n",
    "        file_names[name[1]][name[0]].append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training BernoulliNB...\n",
      "Training SGDClassifier...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training BernoulliNB...\n",
      "Training SGDClassifier...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training BernoulliNB...\n",
      "Training SGDClassifier...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training BernoulliNB...\n",
      "Training SGDClassifier...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training BernoulliNB...\n",
      "Training SGDClassifier...\n",
      "Training MultinomialNB...\n",
      "Training ComplementNB...\n",
      "Training BernoulliNB...\n",
      "Training SGDClassifier...\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import re\n",
    "from joblib import dump, load\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "execution_results = []\n",
    "# Define your models here:\n",
    "# [model, *dict* with params to be tested, *list* of ONE item with the scaler to be used]\n",
    "models = [\n",
    "    [MultinomialNB(),\n",
    "        {\"alpha\": [0.1, 0.2, 0.4, 0.6, 0.8, 1]},\n",
    "        []],\n",
    "    [ComplementNB(),\n",
    "        {\"alpha\": [0.1, 0.2, 0.4, 0.6, 0.8, 1]},\n",
    "        []],\n",
    "    [SGDClassifier(n_jobs=-1, max_iter=1000),\n",
    "        {\"alpha\": 10.0 ** -np.arange(1,7)},\n",
    "        []],\n",
    "]\n",
    "\n",
    "best_score = 0\n",
    "best_clf = None\n",
    "for vectorizer_type in file_names.keys():\n",
    "    for train_file, test_file in zip(file_names[vectorizer_type][\"train\"], file_names[vectorizer_type][\"test\"]):\n",
    "        X_train = sparse.load_npz(\"./vectorizers/{}\".format(train_file))\n",
    "        X_test = sparse.load_npz(\"./vectorizers/{}\".format(test_file))\n",
    "\n",
    "        for classifier in models: \n",
    "            print(\"Training {}...\".format(type(classifier[0]).__name__))\n",
    "            begin_time = datetime.datetime.now()\n",
    "            if classifier[1]:\n",
    "                # Train with grid search with cross-validation if parameters are provided\n",
    "                grid = GridSearchCV(estimator=classifier[0], param_grid=classifier[1], cv=3,\n",
    "                                    n_jobs=-1)\n",
    "                # Scale the dataset if needed, else, use the normal dataset\n",
    "                grid.fit(X_train if not classifier[2] else classifier[2][0].fit_transform(X_train), y_train)\n",
    "                # Select the best classifier obtained through grid search\n",
    "                clf = grid.best_estimator_\n",
    "            else:\n",
    "                # Default train if no parameters provided\n",
    "                clf = classifier[0].fit(X_train if not classifier[2] else classifier[2][0].fit_transform(X_train), y_train)\n",
    "            measured_time_train = datetime.datetime.now() - begin_time\n",
    "\n",
    "            # Predict with the test set and labels\n",
    "            begin_time = datetime.datetime.now()\n",
    "            y_pred = clf.predict(X_test if not classifier[2] else classifier[2][0].fit_transform(X_test))\n",
    "            measured_time_test = datetime.datetime.now() - begin_time\n",
    "\n",
    "            # Save all the results in a dictionary\n",
    "            train_results = classification_report(y_train, clf.predict(X_train if not classifier[2] else classifier[2][0].fit_transform(X_train)), target_names=[\"non-depression\", \"depression\"], output_dict=True)\n",
    "            test_results = classification_report(y_test, y_pred, target_names=[\"non-depression\", \"depression\"], output_dict=True)\n",
    "            execution_results.append({\"model\": str(clf),\n",
    "            \"train_accuracy\": train_results[\"accuracy\"],\n",
    "            \"test_accuracy\": test_results[\"accuracy\"],\n",
    "            \"train_results\": train_results,\n",
    "            \"test_results\": test_results,\n",
    "            \"measured_time_train\": str(measured_time_train),\n",
    "            \"measured_time_test\": str(measured_time_test),\n",
    "            \"type\": \"{} with ({}) n-grams\".format(vectorizer_type.upper(), \"-\".join(re.findall(r'\\d+', train_file)))})\n",
    "\n",
    "            # Save the model\n",
    "            if test_results[\"accuracy\"] > best_score:\n",
    "                best_score = test_results[\"accuracy\"]\n",
    "                best_clf = clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Transform the results' dictionary into a pandas dataframe\n",
    "execution_results_df = pd.DataFrame.from_dict(execution_results, orient=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the dataframe to excel and json\n",
    "execution_results_df.to_excel(\"execution_results.xlsx\")\n",
    "execution_results_df.to_json(\"execution_results.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if best_clf is not None:\n",
    "    dump(best_clf, \"./best_model.joblib\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = load(\"./best_model.joblib\")\n",
    "test_sentence = \"\"\n",
    "predicted_result = clf.predict(test_sentence)\n",
    "\n",
    "if hasattr(clf, \"decision_function\"):\n",
    "    predicted_proba = clf.decision_function([test_sentence]) # Probability for each class\n",
    "else:\n",
    "    predicted_proba = clf.predict_proba([test_sentence])[:, 1] # The more positive, the more depressive and viceversa\n",
    "\n",
    "print(predicted_result)\n",
    "print(predicted_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38164bit0e230da09833446789e7a9e442994782",
   "language": "python",
   "display_name": "Python 3.8.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}