{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training datasets...\n",
      "Loading testing datasets...\n",
      "Datasets succesfully loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Loading training datasets...\")\n",
    "df_train_depression = pd.DataFrame(pd.read_json(\"../datasets/training/raw_dep_training_cut_s.jsonl\", lines=True))\n",
    "df_train_control = pd.DataFrame(pd.read_json(\"../datasets/training/raw_ctrl_training_cut_s.jsonl\", lines=True))\n",
    "\n",
    "print(\"Loading testing datasets...\")\n",
    "df_test_depression = pd.DataFrame(pd.read_json(\"../datasets/testing/raw_dep_testing_cut_s.jsonl\", lines=True))\n",
    "df_test_control = pd.DataFrame(pd.read_json(\"../datasets/testing/raw_ctrl_testing_cut_s.jsonl\", lines=True))\n",
    "\n",
    "print(\"Datasets succesfully loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train_depression.append(df_test_control, ignore_index=True)\n",
    "df_test = df_test_depression.append(df_test_control, ignore_index=True)\n",
    "\n",
    "del df_train_depression, df_train_control, df_test_depression, df_test_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_train[\"title\"] = np.where((df_train.title == \"[removed]\"),'', df_train.title)\n",
    "df_train[\"selftext\"] = np.where((df_train.selftext == \"[removed]\"),'', df_train.selftext)\n",
    "df_test[\"title\"] = np.where((df_test.title == \"[removed]\"),'', df_test.title)\n",
    "df_test[\"selftext\"] = np.where((df_test.selftext == \"[removed]\"),'', df_test.selftext)\n",
    "\n",
    "df_train = df_train[df_train[[\"title\", \"selftext\"]].ne('').all(axis=1)]\n",
    "df_test = df_test[df_test[[\"title\", \"selftext\"]].ne('').all(axis=1)]\n",
    "\n",
    "df_train[\"text\"] = df_train[\"title\"] + \" \"  + df_train[\"selftext\"]\n",
    "df_test[\"text\"] = df_test[\"title\"] + \" \" + df_test[\"selftext\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=9771.0, style=ProgressStyle(descriptio…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bd61964e6754259a9118bafb34190cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=2942.0, style=ProgressStyle(descriptio…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ca746701d684bcbba7841180d7cd11d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime\n",
    "import cleantext\n",
    "import re\n",
    "import swifter\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "pst = PorterStemmer()\n",
    "stopwords_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "def pre_process(text: str):\n",
    "    processed = cleantext.clean(text, lower=True, fix_unicode=True, no_punct=True)\n",
    "\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stopwords_set) + r')\\b\\s*')\n",
    "    processed = pattern.sub('', processed)\n",
    "\n",
    "    stemmed_words = [pst.stem(word) for word in word_tokenize(processed)]\n",
    "\n",
    "    return \" \".join(stemmed_words)\n",
    "\n",
    "df_train[\"text\"] = df_train[\"text\"].swifter.apply(lambda x: pre_process(x))\n",
    "df_test[\"text\"] = df_test[\"text\"].swifter.apply(lambda x: pre_process(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df_train = df_train[[\"text\", \"depression_related\"]]\n",
    "df_test = df_test[[\"text\", \"depression_related\"]]\n",
    "\n",
    "df_train.to_json(orient=\"records\", lines=True, force_ascii=True,\n",
    "                 path_or_buf=\"../datasets/training/proc_training.jsonl\")\n",
    "df_test.to_json(orient=\"records\", lines=True, force_ascii=True,\n",
    "                 path_or_buf=\"../datasets/testing/proc_testing.jsonl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of BOW vector: (9771, 22575)\n",
      "\tTotal elapsed time (BOW): 0:00:01.213426 for ngram_range (1, 1)\n",
      "Shape of TFIDF vector: (9771, 22575)\n",
      "\tTotal elapsed time (TFIDF): 0:00:00.048870 for ngram_range (1, 1)\n",
      "\n",
      "Shape of BOW vector: (9771, 404956)\n",
      "\tTotal elapsed time (BOW): 0:00:10.318794 for ngram_range (1, 2)\n",
      "Shape of TFIDF vector: (9771, 404956)\n",
      "\tTotal elapsed time (TFIDF): 0:00:00.418879 for ngram_range (1, 2)\n",
      "\n",
      "Shape of BOW vector: (9771, 382381)\n",
      "\tTotal elapsed time (BOW): 0:00:10.703642 for ngram_range (2, 2)\n",
      "Shape of TFIDF vector: (9771, 382381)\n",
      "\tTotal elapsed time (TFIDF): 0:00:00.205451 for ngram_range (2, 2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import file_manager\n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "file_manager.clear_path(\"./vectorizers\")\n",
    "n_grams = [(1, 1), (1, 2), (2, 2)]\n",
    "for ngram_range in n_grams:\n",
    "    formatted_range = str(ngram_range).strip(\"(\").strip(\")\").replace(\" \", \"\").replace(\",\", \"_\")\n",
    "    file_manager.create_subdir(\"./vectorizers\", formatted_range)\n",
    "\n",
    "for ngram_range in n_grams:\n",
    "    formatted_range = str(ngram_range).strip(\"(\").strip(\")\").replace(\" \", \"\").replace(\",\", \"_\")\n",
    "\n",
    "    begin_time = datetime.datetime.now()\n",
    "    cv = CountVectorizer(ngram_range=ngram_range)\n",
    "    bow = cv.fit_transform(df_train.text.to_list())\n",
    "    np.save(\"./vectorizers/{}/bow\".format(formatted_range), bow)\n",
    "    joblib.dump(cv, \"./vectorizers/{}/bow_vect\".format(formatted_range))\n",
    "\n",
    "    print(\"Shape of BOW vector: {}\".format(bow.shape))\n",
    "    print(\"\\tTotal elapsed time (BOW): {} for ngram_range {}\".format(datetime.datetime.now() - begin_time, ngram_range))\n",
    "\n",
    "    begin_time = datetime.datetime.now()\n",
    "    tf_trans = TfidfTransformer()\n",
    "    tfidf = tf_trans.fit_transform(bow)\n",
    "    np.save(\"./vectorizers/{}/tfidf\".format(formatted_range), bow)\n",
    "    joblib.dump(tf_trans, \"./vectorizers/{}/bow_vect\".format(formatted_range))\n",
    "\n",
    "    print(\"Shape of TFIDF vector: {}\".format(tfidf.shape))\n",
    "    print(\"\\tTotal elapsed time (TFIDF): {} for ngram_range {}\\n\".format(datetime.datetime.now() - begin_time, ngram_range))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python38164bit0e230da09833446789e7a9e442994782",
   "language": "python",
   "display_name": "Python 3.8.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}